{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ›ï¸ Archimedes Chess AI - One-Click Setup\n",
    "\n",
    "**High-Performance Chess AI with ResNet, AMP, and Advanced MCTS**\n",
    "\n",
    "## ğŸš€ Quick Start\n",
    "\n",
    "1. **Aktiviere GPU**: `Laufzeit` â†’ `Laufzeittyp Ã¤ndern` â†’ `Hardwarebeschleuniger: GPU`\n",
    "2. **FÃ¼hre die Setup-Zelle aus** (unten)\n",
    "3. **Fertig!** Das Training startet automatisch\n",
    "\n",
    "## âœ¨ Features (v2.0)\n",
    "\n",
    "- **ResNet-basiertes TPN**: 10 Residual Blocks mit Batch Normalization\n",
    "- **Automatic Mixed Precision (AMP)**: 2-3x schnelleres Training\n",
    "- **Time-based Iterative Deepening**: Intelligente Suchtiefensteuerung\n",
    "- **LRU Transposition Table**: Effiziente Cache-Verwaltung\n",
    "- **Q-Value Normalization**: Stabilere MCTS-Suche\n",
    "- **Advanced Schedulers**: CosineAnnealingWarmRestarts fÃ¼r bessere Konvergenz\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ¯ ONE-CLICK SETUP & TRAINING\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# Diese Zelle macht ALLES:\n",
    "# 1. Installiert Dependencies\n",
    "# 2. Klont das Repository (oder verwendet hochgeladene Dateien)\n",
    "# 3. ÃœberprÃ¼ft GPU-VerfÃ¼gbarkeit\n",
    "# 4. Startet das Training mit optimalen Parametern\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ›ï¸  ARCHIMEDES CHESS AI - ONE-CLICK SETUP\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 1: Install Dependencies\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“¦ [1/4] Installing dependencies...\\n\")\n",
    "\n",
    "# Check if we're in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # Install PyTorch with CUDA support\n",
    "    !pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "    \n",
    "    # Install other dependencies\n",
    "    !pip install -q chess python-chess torch-geometric tqdm psutil\n",
    "    \n",
    "    print(\"âœ… Dependencies installed!\\n\")\n",
    "else:\n",
    "    print(\"âš ï¸  Not running in Colab. Assuming dependencies are already installed.\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 2: Repository Setup\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ“‚ [2/4] Setting up repository...\\n\")\n",
    "\n",
    "# Option A: Clone from GitHub (replace with your repo URL)\n",
    "REPO_URL = \"\"  # Leave empty if uploading manually\n",
    "\n",
    "if REPO_URL:\n",
    "    print(f\"   Cloning from: {REPO_URL}\")\n",
    "    !git clone {REPO_URL} archimedes\n",
    "    %cd archimedes\n",
    "    print(\"âœ… Repository cloned!\\n\")\n",
    "else:\n",
    "    # Option B: Check if files are already present\n",
    "    if Path(\"train_end_to_end.py\").exists():\n",
    "        print(\"âœ… Repository files found!\\n\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Repository not found!\")\n",
    "        print(\"   Please either:\")\n",
    "        print(\"   1. Set REPO_URL above and re-run this cell, OR\")\n",
    "        print(\"   2. Upload the project files to Colab manually\\n\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 3: System Check\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸ” [3/4] Checking system...\\n\")\n",
    "\n",
    "import torch\n",
    "\n",
    "print(\"   System Information:\")\n",
    "print(f\"   â”œâ”€ Python: {sys.version.split()[0]}\")\n",
    "print(f\"   â”œâ”€ PyTorch: {torch.__version__}\")\n",
    "print(f\"   â””â”€ CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\n   ğŸ® GPU Information:\")\n",
    "    print(f\"   â”œâ”€ Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   â”œâ”€ CUDA Version: {torch.version.cuda}\")\n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"   â”œâ”€ Memory: {props.total_memory / 1024**3:.1f} GB\")\n",
    "    print(f\"   â”œâ”€ Compute Capability: {props.major}.{props.minor}\")\n",
    "    print(f\"   â””â”€ AMP Support: {'âœ… Yes' if props.major >= 7 else 'âŒ No (requires CC 7.0+)'}\")\n",
    "    \n",
    "    # Determine optimal batch size based on GPU\n",
    "    gpu_mem_gb = props.total_memory / 1024**3\n",
    "    if gpu_mem_gb >= 40:  # A100\n",
    "        batch_size = 64\n",
    "        num_workers = 2\n",
    "    elif gpu_mem_gb >= 15:  # T4, V100\n",
    "        batch_size = 32\n",
    "        num_workers = 1\n",
    "    else:  # Smaller GPUs\n",
    "        batch_size = 16\n",
    "        num_workers = 1\n",
    "    \n",
    "    use_amp = props.major >= 7  # AMP requires Compute Capability 7.0+\n",
    "    \n",
    "    print(f\"\\n   ğŸ“Š Recommended Settings:\")\n",
    "    print(f\"   â”œâ”€ Batch Size: {batch_size}\")\n",
    "    print(f\"   â”œâ”€ Workers: {num_workers}\")\n",
    "    print(f\"   â””â”€ AMP: {'Enabled' if use_amp else 'Disabled'}\")\n",
    "else:\n",
    "    print(\"\\n   âš ï¸  No GPU detected!\")\n",
    "    print(\"   Please enable GPU: Laufzeit â†’ Laufzeittyp Ã¤ndern â†’ GPU\")\n",
    "    print(\"   Training will be VERY slow on CPU!\\n\")\n",
    "    batch_size = 8\n",
    "    num_workers = 1\n",
    "    use_amp = False\n",
    "\n",
    "print(\"\\nâœ… System check complete!\\n\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# STEP 4: Start Training\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(\"ğŸš€ [4/4] Starting training...\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Training parameters (adjust as needed)\n",
    "TOTAL_GAMES = 100          # Number of self-play games\n",
    "TRAINING_ITERATIONS = 500  # Number of training iterations\n",
    "WARMUP_GAMES = 20          # Warmup games before training\n",
    "SCHEDULER = \"cosine\"       # Learning rate scheduler: cosine, plateau, none\n",
    "\n",
    "# Build command\n",
    "cmd = f\"\"\"python train_end_to_end.py \\\n",
    "    --num-workers {num_workers} \\\n",
    "    --total-games {TOTAL_GAMES} \\\n",
    "    --training-iterations {TRAINING_ITERATIONS} \\\n",
    "    --batch-size {batch_size} \\\n",
    "    --warmup-games {WARMUP_GAMES} \\\n",
    "    --scheduler {SCHEDULER} \\\n",
    "    --checkpoint-dir ./checkpoints \\\n",
    "    --save-every 10 \\\n",
    "    {'--use-amp' if use_amp else '--no-amp'}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nğŸ“ Training Configuration:\")\n",
    "print(f\"   â”œâ”€ Total Games: {TOTAL_GAMES}\")\n",
    "print(f\"   â”œâ”€ Training Iterations: {TRAINING_ITERATIONS}\")\n",
    "print(f\"   â”œâ”€ Batch Size: {batch_size}\")\n",
    "print(f\"   â”œâ”€ Workers: {num_workers}\")\n",
    "print(f\"   â”œâ”€ Warmup Games: {WARMUP_GAMES}\")\n",
    "print(f\"   â”œâ”€ Scheduler: {SCHEDULER}\")\n",
    "print(f\"   â””â”€ AMP: {'Enabled' if use_amp else 'Disabled'}\")\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Execute training\n",
    "!{cmd}\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… TRAINING COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nğŸ“ Checkpoints saved in: ./checkpoints/\")\n",
    "print(\"ğŸ“Š Training logs saved in: ./checkpoints/training_logs.db\")\n",
    "print(\"\\nğŸ’¡ Next Steps:\")\n",
    "print(\"   1. Download checkpoints: Files â†’ checkpoints â†’ Download\")\n",
    "print(\"   2. View logs with dashboard.py (requires local setup)\")\n",
    "print(\"   3. Evaluate model with evaluate_elo.py\")\n",
    "print(\"\\nğŸ‰ Happy training!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“Š Optional: View Training Progress\n",
    "\n",
    "If you want to monitor training in real-time, you can use the following cell to display basic metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Display training metrics from database\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "db_path = Path(\"./checkpoints/training_logs.db\")\n",
    "\n",
    "if db_path.exists():\n",
    "    conn = sqlite3.connect(str(db_path))\n",
    "    \n",
    "    # Get epoch summary\n",
    "    print(\"ğŸ“ˆ Training Progress:\\n\")\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT epoch, total_loss, policy_loss, value_loss, lr, top1_accuracy, top5_accuracy FROM epoch_summary ORDER BY epoch DESC LIMIT 10\",\n",
    "        conn\n",
    "    )\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Get hardware stats\n",
    "    print(\"\\n\\nğŸ–¥ï¸  Hardware Utilization (Latest):\\n\")\n",
    "    df_hw = pd.read_sql_query(\n",
    "        \"SELECT gpu_utilization_pct, vram_mb, gpu_temp_c, cpu_load_pct, ram_mb FROM hardware_snapshots ORDER BY timestamp DESC LIMIT 1\",\n",
    "        conn\n",
    "    )\n",
    "    if not df_hw.empty:\n",
    "        print(f\"   GPU Utilization: {df_hw['gpu_utilization_pct'].iloc[0]:.1f}%\")\n",
    "        print(f\"   VRAM Usage: {df_hw['vram_mb'].iloc[0]:.0f} MB\")\n",
    "        print(f\"   GPU Temperature: {df_hw['gpu_temp_c'].iloc[0]:.1f}Â°C\")\n",
    "        print(f\"   CPU Load: {df_hw['cpu_load_pct'].iloc[0]:.1f}%\")\n",
    "        print(f\"   RAM Usage: {df_hw['ram_mb'].iloc[0]:.0f} MB\")\n",
    "    \n",
    "    conn.close()\n",
    "else:\n",
    "    print(\"âš ï¸  No training logs found. Start training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ® Optional: Test the Trained Model\n",
    "\n",
    "After training, you can test the model by playing a few moves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Test the trained model\n",
    "import torch\n",
    "import chess\n",
    "from src.archimedes.model import TPN, SAN, PlanToMoveMapper\n",
    "from src.archimedes.search import ConceptualGraphSearch\n",
    "from pathlib import Path\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint_path = Path(\"./checkpoints/latest_checkpoint.pt\")\n",
    "\n",
    "if checkpoint_path.exists():\n",
    "    print(\"ğŸ® Loading trained model...\\n\")\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Initialize models\n",
    "    tpn = TPN().to(device)\n",
    "    san = SAN().to(device)\n",
    "    mapper = PlanToMoveMapper().to(device)\n",
    "    \n",
    "    # Load weights\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    tpn.load_state_dict(checkpoint[\"tpn_state_dict\"])\n",
    "    san.load_state_dict(checkpoint[\"san_state_dict\"])\n",
    "    mapper.load_state_dict(checkpoint[\"mapper_state_dict\"])\n",
    "    \n",
    "    tpn.eval()\n",
    "    san.eval()\n",
    "    mapper.eval()\n",
    "    \n",
    "    # Create search engine\n",
    "    search = ConceptualGraphSearch(\n",
    "        tpn, san, mapper,\n",
    "        num_simulations=50,\n",
    "        use_transposition_table=True,\n",
    "        use_q_normalization=True\n",
    "    )\n",
    "    \n",
    "    # Play a few moves\n",
    "    board = chess.Board()\n",
    "    print(\"Starting position:\")\n",
    "    print(board)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    \n",
    "    for move_num in range(5):\n",
    "        result = search.search(board, temperature=0.0)\n",
    "        move = result[\"best_move\"]\n",
    "        \n",
    "        print(f\"Move {move_num + 1}: {move}\")\n",
    "        print(f\"   Tactical Value: {result['v_tactical'].item():.3f}\")\n",
    "        print(f\"   MCTS Stats: NPS={result['mcts_stats'].get('nps', 0):.0f}, Depth={result['mcts_stats'].get('avg_depth', 0):.1f}\")\n",
    "        \n",
    "        board.push(move)\n",
    "        print(f\"\\n{board}\\n\")\n",
    "        print(\"â”€\" * 50 + \"\\n\")\n",
    "    \n",
    "    print(\"âœ… Model test complete!\")\n",
    "else:\n",
    "    print(\"âš ï¸  No checkpoint found. Train the model first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ“š Additional Resources\n",
    "\n",
    "- **GitHub Repository**: [Link to your repo]\n",
    "- **Documentation**: See README.md for detailed information\n",
    "- **Paper**: [Link to paper if available]\n",
    "\n",
    "## ğŸ› Troubleshooting\n",
    "\n",
    "### Out of Memory Error\n",
    "- Reduce `batch_size` in the training cell\n",
    "- Disable AMP by setting `use_amp = False`\n",
    "- Reduce number of residual blocks in model.py\n",
    "\n",
    "### Training is slow\n",
    "- Make sure GPU is enabled (Runtime â†’ Change runtime type â†’ GPU)\n",
    "- Enable AMP if your GPU supports it (Compute Capability 7.0+)\n",
    "- Reduce `num_simulations` in search engine\n",
    "\n",
    "### GPU not detected\n",
    "- Go to: Runtime â†’ Change runtime type â†’ Hardware accelerator â†’ GPU\n",
    "- Restart runtime and re-run the setup cell\n",
    "\n",
    "---\n",
    "\n",
    "**Archimedes Chess AI** - High-Performance Chess Engine with Hybrid Architecture\n",
    "\n",
    "*Built with â¤ï¸ using PyTorch, ResNet, and Advanced MCTS*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
