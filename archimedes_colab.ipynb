{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archimedes Chess AI - Google Colab Setup\n",
    "\n",
    "Dieses Notebook f√ºhrt Sie durch die Installation und das Training der Archimedes Schach-KI in Google Colab.\n",
    "\n",
    "## Voraussetzungen\n",
    "\n",
    "1. **GPU aktivieren**: `Laufzeit` ‚Üí `Laufzeittyp √§ndern` ‚Üí `Hardwarebeschleuniger: GPU`\n",
    "2. **Repository klonen oder hochladen** (siehe n√§chste Zelle)\n",
    "\n",
    "## √úbersicht\n",
    "\n",
    "- **Zelle 1**: Installation aller Dependencies\n",
    "- **Zelle 2**: Repository Setup (Git Clone oder Upload)\n",
    "- **Zelle 3**: System-Check (GPU, CUDA)\n",
    "- **Zelle 4**: Optional - System Benchmark\n",
    "- **Zelle 5**: Training starten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 1: Installation aller Dependencies\n",
    "# Diese Zelle installiert alle ben√∂tigten Pakete f√ºr Archimedes\n",
    "\n",
    "print(\"üì¶ Installiere Dependencies...\")\n",
    "\n",
    "# Basis-Dependencies (ohne PyTorch)\n",
    "!pip install -q -r requirements_colab.txt\n",
    "\n",
    "# PyTorch mit CUDA Support f√ºr Colab\n",
    "# Colab unterst√ºtzt normalerweise CUDA 11.8 oder 12.1\n",
    "# Wir verwenden CUDA 11.8 als Standard (funktioniert mit den meisten Colab GPUs)\n",
    "print(\"\\nüî• Installiere PyTorch mit CUDA Support...\")\n",
    "!pip install -q torch torchvision --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "print(\"\\n‚úÖ Installation abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repository Setup\n",
    "\n",
    "W√§hlen Sie eine der folgenden Optionen:\n",
    "\n",
    "**Option A**: Git Clone (empfohlen, wenn Repository auf GitHub/GitLab ist)\n",
    "**Option B**: Upload (wenn Sie das Projekt lokal haben)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Git Clone\n",
    "# Ersetzen Sie <repository_url> mit der URL Ihres Repositories\n",
    "# Beispiel: https://github.com/username/Projekt-Archimedes.git\n",
    "\n",
    "# !git clone <repository_url>\n",
    "# %cd Projekt-Archimedes\n",
    "\n",
    "# Option B: Upload (f√ºr lokale Entwicklung)\n",
    "# Entkommentieren Sie die folgenden Zeilen und laden Sie das Projekt hoch\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "# import os\n",
    "# \n",
    "# uploaded = files.upload()\n",
    "# for filename in uploaded.keys():\n",
    "#     if filename.endswith('.zip'):\n",
    "#         with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#             zip_ref.extractall('.')\n",
    "#         print(f\"‚úÖ {filename} entpackt\")\n",
    "# \n",
    "# # Finde den Projektordner\n",
    "# project_dirs = [d for d in os.listdir('.') if os.path.isdir(d) and 'archimedes' in d.lower()]\n",
    "# if project_dirs:\n",
    "#     %cd {project_dirs[0]}\n",
    "\n",
    "# F√ºr dieses Beispiel nehmen wir an, dass das Repository bereits geklont wurde\n",
    "# Wenn Sie Option A oder B verwenden, kommentieren Sie die folgende Zeile aus:\n",
    "print(\"‚ö†Ô∏è Bitte w√§hlen Sie Option A oder B oben aus und f√ºhren Sie diese Zelle erneut aus!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zelle 3: System-Check\n",
    "# √úberpr√ºft GPU-Verf√ºgbarkeit und CUDA-Version\n",
    "\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SYSTEM INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA verf√ºgbar: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nüéÆ GPU Information:\")\n",
    "    print(f\"   GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"   cuDNN Version: {torch.backends.cudnn.version()}\")\n",
    "    \n",
    "    props = torch.cuda.get_device_properties(0)\n",
    "    print(f\"   GPU Speicher: {props.total_memory / 1024**3:.2f} GB\")\n",
    "    print(f\"   Compute Capability: {props.major}.{props.minor}\")\n",
    "    print(f\"   Multiprocessors: {props.multi_processor_count}\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Keine GPU gefunden!\")\n",
    "    print(\"   Bitte aktivieren Sie GPU: Laufzeit ‚Üí Laufzeittyp √§ndern ‚Üí GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: System Benchmark\n",
    "\n",
    "F√ºhren Sie diese Zelle aus, um Ihre Hardware zu benchmarken und optimale Trainingsparameter zu erhalten.\n",
    "\n",
    "**Hinweis**: Der Benchmark kann einige Minuten dauern. Sie k√∂nnen ihn √ºberspringen und direkt mit dem Training beginnen (die Skripte haben bereits gute Defaults f√ºr Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: System Benchmark\n",
    "# √úberspringt GPU-Tests f√ºr schnellere Ausf√ºhrung (empfohlen f√ºr Colab)\n",
    "\n",
    "!python benchmark_system.py --skip-gpu-test\n",
    "\n",
    "print(\"\\n‚úÖ Benchmark abgeschlossen!\")\n",
    "print(\"Die Ergebnisse wurden in 'benchmark_results.json' gespeichert.\")\n",
    "print(\"Die Trainingsskripte verwenden diese automatisch mit --auto-config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training starten\n",
    "\n",
    "W√§hlen Sie eines der folgenden Trainingsskripte:\n",
    "\n",
    "1. **End-to-End Training** (empfohlen): Trainiert TPN und SAN zusammen durch Self-Play\n",
    "2. **TPN Training**: Trainiert nur das Tactical Perception Network\n",
    "3. **SAN Training**: Trainiert nur das Strategic Abstraction Network\n",
    "\n",
    "### End-to-End Training (Self-Play)\n",
    "\n",
    "Dies ist die empfohlene Methode f√ºr das vollst√§ndige Training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End-to-End Training mit automatischer Konfiguration\n",
    "# --auto-config verwendet die Benchmark-Ergebnisse f√ºr optimale Parameter\n",
    "\n",
    "# Parameter anpassen:\n",
    "total_games = 100  # Anzahl der Self-Play-Spiele\n",
    "training_iterations = 1000  # Anzahl der Training-Iterationen\n",
    "\n",
    "# Starte Training\n",
    "!python train_end_to_end.py \\\n",
    "    --auto-config \\\n",
    "    --total-games {total_games} \\\n",
    "    --training-iterations {training_iterations}\n",
    "\n",
    "print(\"\\n‚úÖ Training abgeschlossen!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: TPN Training (nur Tactical Network)\n",
    "\n",
    "Falls Sie nur das TPN trainieren m√∂chten, ben√∂tigen Sie zuerst einen Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPN Training Beispiel\n",
    "# Hinweis: Sie ben√∂tigen zuerst einen Datensatz mit create_dataset.py\n",
    "\n",
    "# !python train_tpn.py \\\n",
    "#     --dataset-dir ./data/shards_tpn \\\n",
    "#     --auto-config \\\n",
    "#     --epochs 20\n",
    "\n",
    "print(\"‚ö†Ô∏è Diese Zelle ist auskommentiert, da ein Datensatz ben√∂tigt wird.\")\n",
    "print(\"   Verwenden Sie create_dataset.py, um einen Datensatz zu erstellen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: SAN Training (nur Strategic Network)\n",
    "\n",
    "Falls Sie nur das SAN trainieren m√∂chten, ben√∂tigen Sie zuerst einen Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAN Training Beispiel\n",
    "# Hinweis: Sie ben√∂tigen zuerst einen Datensatz mit create_dataset.py\n",
    "\n",
    "# !python train_san.py \\\n",
    "#     --dataset-dir ./data/shards_san \\\n",
    "#     --auto-config \\\n",
    "#     --epochs 20\n",
    "\n",
    "print(\"‚ö†Ô∏è Diese Zelle ist auskommentiert, da ein Datensatz ben√∂tigt wird.\")\n",
    "print(\"   Verwenden Sie create_dataset.py, um einen Datensatz zu erstellen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model speichern und laden\n",
    "\n",
    "Nach dem Training k√∂nnen Sie das Modell speichern und sp√§ter wieder laden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beispiel: Model speichern\n",
    "# (Dies sollte normalerweise im Trainingsskript integriert sein)\n",
    "\n",
    "import torch\n",
    "from src.archimedes.model import TPN, SAN, PlanToMoveMapper\n",
    "\n",
    "# Beispiel-Code zum Speichern (anpassen nach Bedarf):\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# tpn = TPN().to(device)\n",
    "# san = SAN().to(device)\n",
    "# mapper = PlanToMoveMapper().to(device)\n",
    "# \n",
    "# # ... Training ...\n",
    "# \n",
    "# # Speichern\n",
    "# torch.save({\n",
    "#     'tpn_state_dict': tpn.state_dict(),\n",
    "#     'san_state_dict': san.state_dict(),\n",
    "#     'mapper_state_dict': mapper.state_dict(),\n",
    "# }, 'archimedes_model.pth')\n",
    "# \n",
    "# print(\"‚úÖ Model gespeichert als 'archimedes_model.pth'\")\n",
    "\n",
    "print(\"üìù Verwenden Sie diesen Code, um Modelle zu speichern/laden.\")\n",
    "print(\"   Passen Sie die Pfade und Variablennamen an Ihr Training an.\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
